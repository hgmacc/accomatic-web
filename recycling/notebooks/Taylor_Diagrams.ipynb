{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ensemble import *\n",
    "from ts_comp_db import ts_comp_db\n",
    "from import_model import read_geotop, read_forcing\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import aci\n",
    "\n",
    "import random\n",
    "import math\n",
    "from statistics import mean, stdev\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook \n",
    "from bokeh.layouts import row, gridplot\n",
    "from bokeh.models import ColumnDataSource, BoxAnnotation,Label, LabelSet, Span, Range1d\n",
    "from bokeh.io import export_png, export_svgs\n",
    "from bokeh.palettes import brewer, d3\n",
    "\n",
    "# DEGREE OF CONFIDENCE INTERVAL TO CALCULATE\n",
    "confidence = 0.95\n",
    "\n",
    "# Should I get observations from the Database or from pickle\n",
    "get_fresh_db = False\n",
    "\n",
    "# Model results from text file or from pickle\n",
    "get_fresh_local = False\n",
    "\n",
    "# Observations\n",
    "obs_pickle = \"annual-pickles/point_obs_dict.pickle\"\n",
    "obs_pickle_path = Path(obs_pickle)\n",
    "\n",
    "# Simple GEOtop models\n",
    "era5_geotop_simple_pickle = \"annual-pickles/era5_geotop_simple_dict.pickle\"\n",
    "era5_geotop_simple_pickle_path = Path(era5_geotop_simple_pickle)\n",
    "\n",
    "jra55_geotop_simple_pickle = \"annual-pickles/jra55_geotop_simple_dict.pickle\"\n",
    "jra55_geotop_simple_pickle_path = Path(jra55_geotop_simple_pickle)\n",
    "\n",
    "# Complex GEOtop models\n",
    "era5_geotop_complex_pickle = \"annual-pickles/era5_geotop_complex_dict.pickle\"\n",
    "era5_geotop_complex_pickle_path = Path(era5_geotop_complex_pickle)\n",
    "\n",
    "jra55_geotop_complex_pickle = \"annual-pickles/jra55_geotop_complex_dict.pickle\"\n",
    "jra55_geotop_complex_pickle_path = Path(jra55_geotop_complex_pickle)\n",
    "\n",
    "# Simple focing-based models\n",
    "era5_forcing_pickle = \"annual-pickles/era5_forcing_dict.pickle\"\n",
    "era5_forcing_pickle_path = Path(era5_forcing_pickle)\n",
    "\n",
    "jra55_forcing_pickle = \"annual-pickles/jra55_forcing_dict.pickle\"\n",
    "jra55_forcing_pickle_path = Path(jra55_forcing_pickle)\n",
    "\n",
    "# These are the points I'm investigating\n",
    "ts_points = ['NGO-RC-167_ST01',\n",
    "'NGO-RC-167_ST03',\n",
    "'NGO-RC-167_ST04',\n",
    "'NGO-RC-167_ST02',\n",
    "'NGO-RC-166_ST01',\n",
    "'NGO-RC-166_ST03',\n",
    "'NGO-RC-166_ST02',\n",
    "'NGO-RC-169_ST01',\n",
    "'NGO-RC-169_ST05',\n",
    "'NGO-RC-169_ST03',\n",
    "'NGO-RC-169_ST04',\n",
    "'NGO-RC-169_ST02',\n",
    "'NGO-RC-168_ST02',\n",
    "'NGO-RC-168_ST03',\n",
    "'NGO-RC-168_ST04',\n",
    "'NGO-RC-168_ST01',\n",
    "'NGO-RC-163_ST03',\n",
    "'NGO-RC-163_ST02',\n",
    "'NGO-RC-163_ST04',\n",
    "'NGO-RC-163_ST01',\n",
    "'NGO-RC-171_ST02',\n",
    "'NGO-RC-171_ST03',\n",
    "'NGO-RC-171_ST01',\n",
    "'NGO-RC-170_ST02',\n",
    "'NGO-RC-170_ST01',\n",
    "'NGO-RC-170_ST03',\n",
    "'NGO-RC-170_ST04',\n",
    "'Bushloggers_BS03',\n",
    "'Bushloggers_BS02',\n",
    "'Bushloggers_BS01',\n",
    "'Bushloggers_BS04',\n",
    "'NGO-RC-165_ST03',\n",
    "'NGO-RC-165_ST04',\n",
    "'NGO-RC-165_ST02',\n",
    "'NGO-RC-165_ST01',\n",
    "'NGO-RC-164_ST04',\n",
    "'NGO-RC-164_ST01',\n",
    "'NGO-RC-164_ST03',\n",
    "'NGO-RC-162_ST04',\n",
    "'NGO-RC-162_ST03',\n",
    "'NGO-RC-162_ST01',\n",
    "'NGO-RC-162_ST02',\n",
    "'NGO-DD-1004_ST01',\n",
    "'NGO-DD-1004_ST03',\n",
    "'NGO-DD-1004_ST02',\n",
    "'NGO-RC-172_ST03',\n",
    "'NGO-RC-172_ST01',\n",
    "'NGO-RC-172_ST02',\n",
    "'NGO-RC-172_ST04',\n",
    "'NGO-DD-2005_ST04',\n",
    "'NGO-DD-2005_ST03',\n",
    "'NGO-DD-2005_ST02',\n",
    "'NGO-DD-2005_ST01',\n",
    "'NGO-DD-2012_ST02',\n",
    "'NGO-DD-2012_ST03',\n",
    "'NGO-DD-2012_ST01',\n",
    "'NGO-DD-2012_ST04',\n",
    "'NGO-DD-2006_ST04',\n",
    "'NGO-DD-2006_ST03',\n",
    "'NGO-DD-2006_ST02',\n",
    "'NGO-DD-2006_ST01',\n",
    "'NGO-DD-2011_ST03',\n",
    "'NGO-DD-2011_ST02',\n",
    "'NGO-DD-2011_ST04',\n",
    "'NGO-DD-2013_ST03',\n",
    "'NGO-DD-2004_ST04',\n",
    "'NGO-DD-2004_ST02',\n",
    "'NGO-DD-2004_ST01',\n",
    "'NGO-DD-2013_ST01',\n",
    "'NGO-DD-2013_ST02',\n",
    "'NGO-DD-2013_ST04',\n",
    "'NGO-DD-2007_ST02',\n",
    "'NGO-DD-1005_ST02',\n",
    "'NGO-DD-1005_ST04',\n",
    "'NGO-DD-1005_ST03',\n",
    "'NGO-DD-2035_ST03',\n",
    "'NGO-DD-2035_ST04',\n",
    "'NGO-DD-2035_ST02',\n",
    "'NGO-DD-1009_ST04',\n",
    "'NGO-DD-1009_ST02',\n",
    "'NGO-DD-1009_ST01',\n",
    "'NGO-DD-1009_ST03',\n",
    "'NGO-DD-2014_ST03',\n",
    "'NGO-DD-2014_ST04',\n",
    "'NGO-DD-2014_ST02',\n",
    "'NGO-DD-2014_ST01',\n",
    "'NGO-DD-2015_ST03',\n",
    "'NGO-DD-2015_ST04',\n",
    "'NGO-DD-2015_ST02',\n",
    "'NGO-DD-2015_ST01',\n",
    "'NGO-DD-2016_ST03',\n",
    "'NGO-DD-2016_ST01',\n",
    "'NGO-DD-2016_ST02',\n",
    "'NGO-DD-2016_ST04',\n",
    "'NGO-DD-1010_ST01',\n",
    "'NGO-DD-1010_ST03',\n",
    "'NGO-DD-1010_ST04',\n",
    "'NGO-DD-2019_ST04',\n",
    "'NGO-DD-2019_ST03',\n",
    "'NGO-DD-2019_ST01',\n",
    "'NGO-DD-2019_ST02',\n",
    "'NGO-DD-1011_ST02',\n",
    "'NGO-DD-1011_ST03',\n",
    "'NGO-DD-1011_ST01',\n",
    "'NGO-DD-2018_ST01',\n",
    "'NGO-DD-2018_ST03',\n",
    "'NGO-DD-2018_ST02',\n",
    "'NGO-DD-1012_ST04',\n",
    "'NGO-DD-1012_ST03',\n",
    "'NGO-DD-1012_ST02',\n",
    "'NGO-DD-1012_ST01',\n",
    "'NGO-GU-1014_ST02',\n",
    "'NGO-GU-1014_ST04',\n",
    "'NGO-GU-1014_ST01',\n",
    "'NGO-DD-2009_ST01',\n",
    "'NGO-DD-2009_ST04',\n",
    "'NGO-DD-2009_ST02',\n",
    "'NGO-DD-2033_ST01',\n",
    "'NGO-DD-2033_ST04',\n",
    "'NGO-DD-2033_ST03',\n",
    "'NGO-DD-2033_ST02',\n",
    "'NGO-DD-2008_ST04',\n",
    "'NGO-DD-2008_ST02',\n",
    "'NGO-DD-2008_ST01',\n",
    "'NGO-DD-2029_ST04',\n",
    "'NGO-DD-2020_ST02',\n",
    "'NGO-DD-2020_ST03',\n",
    "'NGO-DD-2023_ST02',\n",
    "'NGO-DD-2023_ST03',\n",
    "'NGO-DD-2023_ST01',\n",
    "'NGO-DD-2023_ST04',\n",
    "'NGO-DD-2032_ST04',\n",
    "'NGO-DD-2032_ST03',\n",
    "'NGO-DD-2032_ST02',\n",
    "'NGO-DD-2026_ST02',\n",
    "'NGO-DD-2026_ST03',\n",
    "'NGO-DD-2026_ST04',\n",
    "'NGO-DD-1011_ST04',\n",
    "'NGO-DD-2030_ST03',\n",
    "'NGO-DD-2030_ST01',\n",
    "'NGO-DD-2030_ST02',\n",
    "'NGO-DD-2030_ST04',\n",
    "'NGO-DD-1010_ST02',\n",
    "'NGO-DD-2020_ST04',\n",
    "'NGO-DD-2020_ST01',\n",
    "'NGO-DD-2018_ST04',\n",
    "'NGO-DD-2026_ST01',\n",
    "'NGO-RC-164_ST02',\n",
    "'NGO-RC-171_ST04',\n",
    "'NGO-DD-1005_ST01',\n",
    "'NGO-DD-2004_ST03',\n",
    "'NGO-DD-2007_ST04',\n",
    "'NGO-DD-2007_ST01',\n",
    "'NGO-DD-2007_ST03',\n",
    "'NGO-DD-2032_ST01',\n",
    "'NGO-DD-2035_ST01',\n",
    "'NGO-DD-2011_ST01',\n",
    "'NGO-DD-2029_ST01',\n",
    "'NGO-DD-2008_ST03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET OBSERVATION DATA FROM DB - if they need to be fresh, or if no pickle exists\n",
    "if (get_fresh_db or not obs_pickle_path.is_file()):\n",
    "    user_name = \"readonly\"\n",
    "    password = \"Cup7Quan0awP\"\n",
    "    host = \"permafrost.gcrc.carleton.ca\"\n",
    "    db_name = \"observations\"\n",
    "\n",
    "    # Connect to the database\n",
    "    pf_db = ts_comp_db (host, db_name, user_name, password)\n",
    "\n",
    "\n",
    "    # Get data for the selected points as a dictionary of Series\n",
    "    point_obs_dict = pf_db.get_point_daily_ts_dict(ts_points)\n",
    "\n",
    "    # Close out DB connection\n",
    "    pf_db.close()\n",
    "    \n",
    "    pd.to_pickle(point_obs_dict, obs_pickle)\n",
    "\n",
    "else:\n",
    "    point_obs_dict = pd.read_pickle(obs_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET MODEL RESULTS FROM LOCAL DISK\n",
    "\n",
    "# Get model results from text files - if they need to be fresh, or if no pickle exists\n",
    "if (get_fresh_local or not (era5_geotop_simple_pickle_path.is_file() and jra55_geotop_simple_pickle_path.is_file() and era5_geotop_complex_pickle_path.is_file() and jra55_geotop_complex_pickle_path.is_file())):\n",
    "    # Read geotop results from the outs directory\n",
    "    #point_model_dict = read_geotop(\"era5_outs\",4)\n",
    "    #pd.to_pickle(point_model_dict, models_pickle)\n",
    "    \n",
    "    era5_geotop_simple_dict = read_geotop(\"era5_simple_results\",4)\n",
    "    pd.to_pickle(era5_geotop_simple_dict, era5_geotop_simple_pickle)\n",
    "    \n",
    "    jra55_geotop_simple_dict = read_geotop(\"jra55_simple_results\",4)\n",
    "    pd.to_pickle(jra55_geotop_simple_dict, jra55_geotop_simple_pickle)\n",
    "    \n",
    "    era5_geotop_complex_dict = read_geotop(\"era5_compleTx_results\",4)\n",
    "    pd.to_pickle(era5_geotop_complex_dict, era5_geotop_complex_pickle)\n",
    "    \n",
    "    jra55_geotop_complex_dict = read_geotop(\"jra55_complex_results\",4)\n",
    "    pd.to_pickle(jra55_geotop_complex_dict, jra55_geotop_complex_pickle)\n",
    "else:\n",
    "    #point_model_dict = pd.read_pickle(models_pickle)\n",
    "    era5_geotop_simple_dict = pd.read_pickle(era5_geotop_simple_pickle)\n",
    "    jra55_geotop_simple_dict = pd.read_pickle(jra55_geotop_simple_pickle)\n",
    "    \n",
    "    era5_geotop_complex_dict = pd.read_pickle(era5_geotop_complex_pickle)\n",
    "    jra55_geotop_complex_dict = pd.read_pickle(jra55_geotop_complex_pickle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ERA5 AIR-3 MODEL FROM LOCAL DISK\n",
    "\n",
    "# Get model results from text files - if they need to be fresh, or if no pickle exists\n",
    "if (get_fresh_local or not (era5_forcing_pickle_path.is_file() and jra55_forcing_pickle_path.is_file())):\n",
    "    # Read forcing results from the directory\n",
    "    #point_forcing_dict = read_forcing(\"era5_forcing\",\"ERA5\", 5)\n",
    "    #pd.to_pickle(point_forcing_dict, era5_forcing_pickle)\n",
    "    \n",
    "    era5_forcing_dict = read_forcing(\"era5_forcing\",\"ERA5\", 5)\n",
    "    pd.to_pickle(era5_forcing_dict, era5_forcing_pickle)\n",
    "    \n",
    "    jra55_forcing_dict = read_forcing(\"jra55_forcing\",\"JRA55\", 5)\n",
    "    pd.to_pickle(jra55_forcing_dict, jra55_forcing_pickle)\n",
    "else:\n",
    "    #point_forcing_dict = pd.read_pickle(jra55_forcing_pickle)\n",
    "    era5_forcing_dict = pd.read_pickle(era5_forcing_pickle)\n",
    "    jra55_forcing_dict = pd.read_pickle(jra55_forcing_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_details = pd.read_csv(\"point_details.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble object for each observation point\n",
    "ensemble_dict = {}\n",
    "\n",
    "for idx, row_vals in point_details.iterrows():\n",
    "    ensemble_dict[idx] = ensemble(idx, row_vals[\"latitude_dd\"], row_vals[\"longitude_dd\"], 0, row_vals[\"elevation_m\"], row_vals[\"ground_type\"])\n",
    "    ensemble_dict[idx].set_observation_ts(point_obs_dict[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GEOtop results to each model ensemble\n",
    "for i in point_obs_dict:\n",
    "    ensemble_dict[i].add_model_ts(era5_geotop_simple_dict[i], \"GT-ERA5\")\n",
    "    ensemble_dict[i].add_model_ts(jra55_geotop_simple_dict[i], \"GT-JRA55\")\n",
    "    ensemble_dict[i].add_model_ts(era5_geotop_complex_dict[i], \"GT-BSnow-ERA5\")\n",
    "    ensemble_dict[i].add_model_ts(jra55_geotop_complex_dict[i], \"GT-BSnow-JRA55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in era5_forcing_dict:\n",
    "    ensemble_dict[i].add_model_ts(era5_forcing_dict[i]/2, \"ERA5/2\")\n",
    "\n",
    "for i in jra55_forcing_dict:\n",
    "    ensemble_dict[i].add_model_ts(jra55_forcing_dict[i]/2, \"JRA55/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_start_date = '01-Sep-2015'\n",
    "\n",
    "#all_accordance_funcs = {'RMSE':rmse, 'MAE':mae, 'r^2':r_squared, 'Willmott d':willmott_d,\n",
    "#                        \"Willmott d one\":willmott_d_one, \"Willmott refined d\":willmott_refined_d, \n",
    "#                        \"Nash-Sutcliffe efficiency\":nse, \"E one\":nse_one}\n",
    "\n",
    "#all_accordance_funcs = {'r^2':r_squared, 'MAE':mae,'RMSE':rmse, \"Nash-Sutcliffe efficiency\":nse, 'Willmott d':willmott_d,\n",
    "                        #\"Willmott d one\":willmott_d_one, \"Willmott refined d\":willmott_refined_d, \"E one\":nse_one}\n",
    "\n",
    "all_accordance_funcs = {'RMSE':rmse, \"Willmott d one\":willmott_d_one, \"E one\":nse_one}\n",
    "\n",
    "subscripted_measure_names = {'r^2':'r²', 'Nash-Sutcliffe efficiency':'NSE', 'MAE':'MAE', 'RMSE':'RMSE', 'Willmott d':'d', \n",
    "                             'Willmott d one':'d₁', \"Willmott refined d\":'dᵣ', \"E one\":'E₁'}\n",
    "\n",
    "all_accordance_results = {}\n",
    "all_accordance_rankings = {}\n",
    "\n",
    "for m in all_accordance_funcs:\n",
    "    accordance_func = all_accordance_funcs[m]\n",
    "\n",
    "    # Split all observation and model time-series into years based on years present in observations\n",
    "    # Then calculated accordances on the split timeseries for the complete years, store results\n",
    "    # in dictionary accordance_dict_year, key is name of point, data is dataframe containing accordances\n",
    "    # of every model in the ensemble for years for which there's complete observations\n",
    "\n",
    "    over_one_year = []\n",
    "    accordance_dict_year = {}\n",
    "\n",
    "    for i in point_obs_dict:\n",
    "\n",
    "        obs_ensemble_ts = ensemble_dict[i].get_observation_ts()\n",
    "\n",
    "        model_ensemble_ts = ensemble_dict[i].get_model_ts()\n",
    "\n",
    "        split_obs_by_year = aci.year_split(obs_ensemble_ts, year_start_date)\n",
    "\n",
    "        if (len(split_obs_by_year) > 0):\n",
    "            over_one_year.append(i)\n",
    "\n",
    "            accordance_df = pd.DataFrame(index = list(split_obs_by_year.keys()))\n",
    "\n",
    "            # Iterate through models\n",
    "            # j is the name of the model, split_obs_by_year and split_model_by_year are dictionaries\n",
    "            # containing the time-series to be compared. Can compare with a for loop, store results in a dataframe\n",
    "            # indexed by date of the start of year where each column is a model and the data is the accordance.\n",
    "            for j in model_ensemble_ts:\n",
    "                split_model_by_year = aci.year_split(model_ensemble_ts[j], year_start_date)\n",
    "                model_accordance = []\n",
    "                # Iterating through the time-periods\n",
    "                for k in split_obs_by_year:\n",
    "                    accordance = accordance_func(split_model_by_year[k], split_obs_by_year[k], 2)\n",
    "                    model_accordance.append(accordance)\n",
    "                accordance_df[j] = model_accordance\n",
    "        accordance_dict_year[i] = accordance_df\n",
    "\n",
    "    # Move accordance data out of dictionary and into a single DataFrame\n",
    "\n",
    "    model_accordance_df =  pd.DataFrame(columns = [\"GT-ERA5\", \"GT-JRA55\", \"GT-BSnow-ERA5\",\n",
    "                                                 \"GT-BSnow-JRA55\", \"ERA5/2\", \"JRA55/2\"])\n",
    "    # Go through the dict of DFs and add name to years\n",
    "    for i in accordance_dict_year:\n",
    "\n",
    "        new_index = ['%s - %s' % (i,x) for x in list(accordance_dict_year[i].index.strftime(\"%Y-%m-%d\"))]\n",
    "        accordance_dict_year[i]['point_idx'] = new_index\n",
    "        reindexed_df = accordance_dict_year[i].set_index('point_idx')\n",
    "        model_accordance_df = model_accordance_df.append(reindexed_df)\n",
    "\n",
    "    all_accordance_results[m] = model_accordance_df\n",
    "    if m in ['RMSE', 'MAE']:\n",
    "        all_accordance_rankings[m] = model_accordance_df.rank(axis=1, method='average', ascending=True)\n",
    "    else:\n",
    "        all_accordance_rankings[m] = model_accordance_df.rank(axis=1, method='average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE\n",
      "Willmott d one\n",
      "E one\n"
     ]
    }
   ],
   "source": [
    "model_means = pd.DataFrame()\n",
    "model_ranks = pd.DataFrame()\n",
    "accordance_max = pd.DataFrame()\n",
    "accordance_min = pd.DataFrame()\n",
    "for m in all_accordance_funcs:\n",
    "    model_means[m] = all_accordance_results[m].mean()\n",
    "    #print(\"Means:\\n\",all_accordance_results[m].mean())\n",
    "    if m in ['RMSE', 'MAE']:\n",
    "        model_ranks[m] = all_accordance_results[m].mean().rank(axis=0, method='average', ascending=True)\n",
    "    else:\n",
    "        model_ranks[m] = all_accordance_results[m].mean().rank(axis=0, method='average', ascending=False)\n",
    "    accordance_max[m] = all_accordance_results[m].max()\n",
    "    accordance_min[m] = all_accordance_results[m].min()\n",
    "        \n",
    "#print(model_means)\n",
    "#print(model_ranks)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Code to calculate confidence intervals based on the regular bootstrap.\n",
    "# This code should not be run if the Bootstrap-T method is being used\n",
    "\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "rank_comparison_dict = {}\n",
    "\n",
    "# Bootstrap steps\n",
    "# 1. x_1, X_2, ...., x_n is the sample drawn from distribution F\n",
    "    # x_n is the accordance value at point _n\n",
    "# 2. u is the mean computed from the sample, so mean(x_1, x_2,...,x_n)\n",
    "# 3. F* is the resampling distribution\n",
    "# 4. x*_1, x*_2,...,x*_n is a resample of the same size as the original sample\n",
    "# 5. u* is the mean of the resample\n",
    "# Bootstrap principle states that F* approximates F\n",
    "# Variation of u is well-approximated by variation of u*\n",
    "\n",
    "# Confidence interval degree is 1 - ci_value %\n",
    "ci_value=0.05\n",
    "resample_size = 0     # if 0, resample size will be same as sample\n",
    "resample_freq = 10000\n",
    "\n",
    "#rank_comparison_dict = {}\n",
    "\n",
    "# positions in the resample lists that represent the upper and lower ci bounds \n",
    "lower_ci = int(round(resample_freq * ci_value/2)) - 1\n",
    "upper_ci = int(round(resample_freq * (1-ci_value/2))) - 1\n",
    "\n",
    "for m in all_accordance_funcs:\n",
    "\n",
    "    rank_comparison_dict[m] = pd.DataFrame()\n",
    "\n",
    "    rank_comparison_dict[m]['mean'] = model_means[m]\n",
    "    rank_comparison_dict[m]['rank'] = model_ranks[m]\n",
    "\n",
    "\n",
    "    # Accordance values for all points\n",
    "    pop_sample = all_accordance_results[m]\n",
    "    \n",
    "    # place to store generated CI values\n",
    "    ci_min_series = pd.Series()\n",
    "    ci_max_series = pd.Series()\n",
    "    \n",
    "    # all values by model\n",
    "    for col in pop_sample:\n",
    "        \n",
    "        current_sample = pop_sample[col]\n",
    "        current_sample_mean = model_means[m].loc[col]\n",
    "        \n",
    "        resample_deltas = []\n",
    "        \n",
    "        # repeat resample_freq times\n",
    "        for i in range(0,resample_freq):\n",
    "            \n",
    "            num_elements = resample_size\n",
    "            \n",
    "            if (resample_size == 0):\n",
    "                num_elements = len(current_sample)\n",
    "            \n",
    "            \n",
    "            # take mean of resample with replacement of num_elements elements, subtract from sample mean\n",
    "            \n",
    "            resample_deltas.append(mean(random.choices(current_sample, k=num_elements)) - current_sample_mean)\n",
    "            \n",
    "        # Sort differences\n",
    "        resample_deltas.sort()\n",
    "        \n",
    "        # Set lower and upper limits of confidence interval for this model\n",
    "        ci_max_series[col] = current_sample_mean - resample_deltas[lower_ci]\n",
    "        ci_min_series[col] = current_sample_mean - resample_deltas[upper_ci]\n",
    "    \n",
    "    # Set the CI min and max values for this measure on all models\n",
    "    rank_comparison_dict[m]['ci_min'] = ci_min_series \n",
    "    rank_comparison_dict[m]['ci_max'] = ci_max_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOOTSTRAP-T CONFIDENCE INTERVALS \n",
    "\n",
    "\n",
    "rank_comparison_dict = {}\n",
    "\n",
    "# Bootstrap-t steps\n",
    "\n",
    "# 1. \n",
    "# 1. x_1, X_2, ...., x_n is the sample drawn from distribution F\n",
    "    # x_n is the accordance value at point _n\n",
    "# 2. u is the mean computed from the sample, so mean(x_1, x_2,...,x_n)\n",
    "# 3. F* is the resampling distribution\n",
    "# 4. x*_1, x*_2,...,x*_n is a resample of the same size as the original sample\n",
    "# 5. u* is the mean of the resample\n",
    "# Bootstrap principle states that F* approximates F\n",
    "# Variation of u is well-approximated by variation of u*\n",
    "\n",
    "# Confidence interval degree is 1 - ci_value %\n",
    "ci_value=0.05\n",
    "resample_size = 0     # if 0, resample size will be same as sample\n",
    "resample_freq = 10000\n",
    "\n",
    "#rank_comparison_dict = {}\n",
    "\n",
    "# positions in the resample lists that represent the upper and lower ci bounds \n",
    "lower_ci = int(round(resample_freq * ci_value/2)) - 1\n",
    "upper_ci = int(round(resample_freq * (1-ci_value/2))) - 1\n",
    "\n",
    "for m in all_accordance_funcs:\n",
    "\n",
    "    rank_comparison_dict[m] = pd.DataFrame()\n",
    "\n",
    "    rank_comparison_dict[m]['mean'] = model_means[m]\n",
    "    rank_comparison_dict[m]['rank'] = model_ranks[m]\n",
    "\n",
    "\n",
    "    # Accordance values for all points\n",
    "    pop_sample = all_accordance_results[m]\n",
    "    \n",
    "    # place to store generated CI values\n",
    "    ci_min_series = pd.Series()\n",
    "    ci_max_series = pd.Series()\n",
    "    \n",
    "    # all values by model\n",
    "    for col in pop_sample:\n",
    "        \n",
    "        \n",
    "        current_sample = pop_sample[col]\n",
    "        current_sample_mean = model_means[m].loc[col]\n",
    "        current_sample_sem = stats.sem(current_sample)\n",
    "        # our values for the 10000 samples\n",
    "        resample_deltas = []\n",
    "        \n",
    "        # repeat resample_freq times\n",
    "        for i in range(0,resample_freq):\n",
    "            \n",
    "            num_elements = resample_size\n",
    "            \n",
    "            if (resample_size == 0):\n",
    "                num_elements = len(current_sample)\n",
    "            \n",
    "            \n",
    "            # Calculate t-value for each bootstrap sample\n",
    "            # formula is t = (sample_mean - population mean) / (sample sd / sqrt(sample size))\n",
    "            # population mean is normalized to 0 for process\n",
    "            \n",
    "            \n",
    "            # take mean of resample with replacement of num_elements elements, subtract from sample mean\n",
    "            # Create bootstrap resample\n",
    "            bootstrap_sample = random.choices(current_sample, k=num_elements)\n",
    "            \n",
    "            # calculate t-statistic for resample\n",
    "            t_stat = (mean(bootstrap_sample) - current_sample_mean)/stats.sem(bootstrap_sample)\n",
    "            #t_stat = (mean(bootstrap_sample) - current_sample_mean)/(stdev(bootstrap_sample)/math.sqrt(len(boostrap_sample))\n",
    "            \n",
    "            #add t-statistic to list of t-stats for CI generation\n",
    "            resample_deltas.append(t_stat)\n",
    "            \n",
    "            #resample_deltas.append((mean(random.choices(current_sample, k=num_elements)) - current_sample_mean)/SE)\n",
    "            \n",
    "        # Sort differences\n",
    "        resample_deltas.sort()\n",
    "        \n",
    "        # Set lower and upper limits of confidence interval for this model\n",
    "        \n",
    "        ci_max_series[col] = current_sample_mean - resample_deltas[lower_ci]*current_sample_sem\n",
    "        ci_min_series[col] = current_sample_mean - resample_deltas[upper_ci]*current_sample_sem\n",
    "    \n",
    "    # Set the CI min and max values for this measure on all models\n",
    "    rank_comparison_dict[m]['ci_min'] = ci_min_series \n",
    "    rank_comparison_dict[m]['ci_max'] = ci_max_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell Bokeh that we'll be outputting to a Jupyter notebook. If the show(variable) function is used instead\n",
    "# of the export_png(variable, filename), it will output interactively in the jupyter notebook\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/luis/accomatic/experiment_results/whisker_plots.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make whisker plots\n",
    "\n",
    "\n",
    "model_inner_colors_dict = {\"GT-ERA5\":brewer['Paired'][12][0], \"GT-JRA55\":brewer['Paired'][12][2],\n",
    "                           \"GT-BSnow-ERA5\":brewer['Paired'][12][4],\"GT-BSnow-JRA55\":brewer['Paired'][12][6],\n",
    "                           \"ERA5/2\":brewer['Paired'][12][8], \"JRA55/2\":brewer['Paired'][12][10]}\n",
    "\n",
    "model_outer_colors_dict = {\"GT-ERA5\":brewer['Paired'][12][1], \"GT-JRA55\":brewer['Paired'][12][3], \n",
    "                           \"GT-BSnow-ERA5\":brewer['Paired'][12][5],\"GT-BSnow-JRA55\":brewer['Paired'][12][7], \n",
    "                           \"ERA5/2\":brewer['Paired'][12][9], \"JRA55/2\":brewer['Paired'][12][11]}\n",
    "\n",
    "for i in rank_comparison_dict:\n",
    "    rank_comparison_dict[i]['outer_colors'] = rank_comparison_dict[i].index.map(model_outer_colors_dict)\n",
    "    rank_comparison_dict[i]['inner_colors'] = rank_comparison_dict[i].index.map(model_inner_colors_dict)\n",
    "\n",
    "annual_ci_graph_list = []\n",
    "\n",
    "for m in all_accordance_funcs:\n",
    "    graph_source_CDS = ColumnDataSource(rank_comparison_dict[m])\n",
    "    \n",
    "    \n",
    "    r = figure(plot_width=800, plot_height=200, title=\"Model mean accordance/95% Confidence Interval - \"+subscripted_measure_names[m], y_range=list(rank_comparison_dict[m].index))\n",
    "    r.toolbar.logo = None\n",
    "    r.toolbar_location = None\n",
    "\n",
    "    r.segment('ci_min','index', 'ci_max', 'index', line_color='outer_colors', line_width=5, source=graph_source_CDS)\n",
    "#    r.rect('ci_min', 'index', 0.02, 0.5, line_color='outer_colors', fill_color='outer_colors', source=graph_source_CDS)\n",
    "#    r.rect('ci_max', 'index', 0.02, 0.5, line_color='outer_colors', fill_color='outer_colors', source=graph_source_CDS)\n",
    "\n",
    "    r.circle(x='mean', y='index', color='outer_colors', size=15, fill_color='inner_colors', line_width=3, source=graph_source_CDS)\n",
    "    #labels = LabelSet(x='rank', y='index', source = graph_source_CDS, text='rank', level='glyph', x_offset=-3, y_offset=10, render_mode='canvas',text_font_size=\"10pt\")\n",
    "    #r.add_layout(labels)\n",
    "\n",
    "    r.title.text_font_size = '13pt'\n",
    "    r.xaxis.axis_label = \"Mean\"\n",
    "    r.yaxis.axis_label = \"Model\"\n",
    "    r.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    r.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "\n",
    "    \n",
    "    annual_ci_graph_list.append(r)\n",
    "\n",
    "ci_plot_grid = gridplot([annual_ci_graph_list[0:1], annual_ci_graph_list[1:2], annual_ci_graph_list[2:3]])\n",
    "\n",
    "export_png(ci_plot_grid, filename=\"experiment_results/whisker_plots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/luis/accomatic/experiment_results/annual_rank_ci.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make model rank range plots\n",
    "\n",
    "model_rank_ranges = {}\n",
    "model_solid_ranks = {}\n",
    "# i is accordance measure\n",
    "for i in rank_comparison_dict:\n",
    "    \n",
    "    rank_comparison_dict[i].sort_values(by='rank', inplace=True)\n",
    "\n",
    "    model_rank_ranges[i] = {}\n",
    "    model_solid_ranks[i] = {}        \n",
    "    for k in rank_comparison_dict[i]['mean'].index:\n",
    "        model_ranks_list = []\n",
    "        model_solid_ranks[i][k] =int(rank_comparison_dict[i]['rank'][k])\n",
    "        for m in rank_comparison_dict[i]['mean'].index:\n",
    "                # if 1_minimum is larger than 2_maximum or 1_max < 2_min then there's no intersection. Otherwise, they intersect\n",
    "\n",
    "            if not ((rank_comparison_dict[i]['ci_min'][k] > rank_comparison_dict[i]['ci_max'][m]) or (rank_comparison_dict[i]['ci_max'][k] < rank_comparison_dict[i]['ci_min'][m])):\n",
    "                # This means there's some overlap\n",
    "                model_ranks_list.append(int(rank_comparison_dict[i]['rank'][m]))\n",
    "        model_ranks_list.sort()\n",
    "        model_rank_ranges[i][k] = model_ranks_list\n",
    "\n",
    "        \n",
    "    y_solid_rank = rank_comparison_dict[i]['rank']\n",
    "    max_rank_dict = {}\n",
    "    min_rank_dict = {}\n",
    "    for n in model_rank_ranges[i]:\n",
    "        max_rank_dict[n] = max(model_rank_ranges[i][n])\n",
    "        min_rank_dict[n] = min(model_rank_ranges[i][n])\n",
    "    rank_comparison_dict[i]['max_rank'] = pd.Series(max_rank_dict)\n",
    "    rank_comparison_dict[i]['min_rank'] = pd.Series(min_rank_dict)\n",
    "    \n",
    "\n",
    "#print(model_rank_ranges)            \n",
    "\n",
    "annual_ci_graph_list = []\n",
    "\n",
    "for m in all_accordance_funcs:\n",
    "    graph_source_CDS = ColumnDataSource(rank_comparison_dict[m])\n",
    "    \n",
    "    \n",
    "    r = figure(plot_width=800, plot_height=200, title=\"Potential annual model ranks - \"+subscripted_measure_names[m], x_range=(0.85,6.15), y_range=list(rank_comparison_dict[m].index))\n",
    "    r.toolbar.logo = None\n",
    "    r.toolbar_location = None\n",
    "\n",
    "    r.segment('min_rank','index', 'max_rank', 'index', line_color='outer_colors', line_width=3, source=graph_source_CDS)\n",
    "    r.rect('min_rank', 'index', 0.02, 0.5, line_color='outer_colors', fill_color='outer_colors', source=graph_source_CDS)\n",
    "    r.rect('max_rank', 'index', 0.02, 0.5, line_color='outer_colors', fill_color='outer_colors', source=graph_source_CDS)\n",
    "\n",
    "    r.circle(x='rank', y='index', color='outer_colors', size=15, fill_color='inner_colors', line_width=3, source=graph_source_CDS)\n",
    "    #labels = LabelSet(x='rank', y='index', source = graph_source_CDS, text='rank', level='glyph', x_offset=-3, y_offset=10, render_mode='canvas',text_font_size=\"10pt\")\n",
    "    #r.add_layout(labels)\n",
    "\n",
    "    r.title.text_font_size = '13pt'\n",
    "    r.xaxis.axis_label = \"Rank\"\n",
    "    r.yaxis.axis_label = \"Model\"\n",
    "    r.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    r.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "    r.xaxis.minor_tick_line_color = None  # turn off x-axis minor ticks\n",
    "    r.xaxis.minor_tick_line_color = None  # turn off x-axis minor ticks\n",
    "    \n",
    "    annual_ci_graph_list.append(r)\n",
    "\n",
    "ci_plot_grid = gridplot([annual_ci_graph_list[0:1], annual_ci_graph_list[1:2], annual_ci_graph_list[2:3]])\n",
    "\n",
    "export_png(ci_plot_grid, filename=\"experiment_results/annual_rank_ci.png\")\n",
    "#show(ci_plot_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}